# ai_search_project
ðŸš€ Just built a fully local, agentic PDF RAG Assistant using FastAPI + LangChain + LangGraph + Ollama + Chroma!

No cloud APIs. 100% private. Semantic search over uploaded PDFs. The LLM intelligently decides when to retrieve context vs. answer directly.

Key tech:
- Ollama (llama3.2:1b + nomic-embed-text embeddings)
- LangGraph's create_react_agent for true agentic behavior
- Chroma for persistent vector DB
- Beautiful React/Tailwind frontend

Who's building local AI apps? What's your favorite Ollama embedding model in 2025?

#AI #RAG #LangChain #Ollama #LocalAI #Python #FastAPI #AgenticAI
